{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções para ciência dos dados:\n",
    "\n",
    "##### As funções aqui produzidas foram feitas por alunos, para todos que desejarem utilizá-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: emoji in c:\\programdata\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import * ## Não julgue.\n",
    "import os.path\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import functools\n",
    "import operator\n",
    "from random import shuffle\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "try:\n",
    "    import emoji;\n",
    "finally:\n",
    "    !pip install emoji --upgrade\n",
    "    import emoji;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdef prob_between(a, b, loc = 0, scale = 1, avg_occurences = 1, n = 1, p = 0.5,  kind = 'norm'):\n",
    "    ## Função para calcular a probabilidade P(X=x), com b <= x <= a\n",
    "    \n",
    "    ## a = Um dos limites de integração, ou, um dos limites para a variável aleatória. \n",
    "    ## b = Um dos limites de integração, ou, um dos limites para a variável aleatória.\n",
    "    ## loc = média; usado para distribuição normal e exponencial.\n",
    "    ## scale = desvio padrão, usado para distribuição normal e exponencial.\n",
    "    ## avg_occurences = Número médio de ocorrências por unidade de tempo, comumente, lambda.\n",
    "    ## n = número de experimentos para as distribuições bernoulli e binomial.\n",
    "    ## p = probabilidade de um evento de bernoulli ou binomial.\n",
    "    ## kind = tipo de distribuição.\n",
    "    \n",
    "    mini, maxi = min(a,b), max(a,b)\n",
    "    \n",
    "    kinds = {\n",
    "        'poisson': False,\n",
    "        'binom': False,\n",
    "        'bern': False,\n",
    "        'expon': False\n",
    "    }\n",
    "    \n",
    "    if kind in kinds:\n",
    "        kinds[kind] = True\n",
    "    else:\n",
    "        return -1\n",
    "        \n",
    "    if kinds['poisson']:\n",
    "        return poison.cdf(maxi, mu = avg_occurences) - poison.cdf(mini,  mu = avg_occurences)\n",
    "    if kinds['binom']:\n",
    "        return binom.cdf(maxi, n = n, p = p) - binom.cdf(mini,  n = n, p = p)\n",
    "    if kinds['bern']:\n",
    "        return 0\n",
    "    if kinds['expon']:\n",
    "        return expon.cdf(maxi, loc = loc, scale = scale) - expon.cdf(mini, loc = loc, scale = scale)\n",
    "    return norm.cdf(maxi, loc=loc, scale=scale) - norm.cdf(mini, loc=loc, scale=scale)\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "def prob_greater(a, loc = 0, scale = 1, avg_occurences = 1, n = 1, p = 0.5,  kind = 'norm'):\n",
    "    \n",
    "    #####-------------------------------------------------#####\n",
    "    ##------ IMPORTANTE: A FUNÇÃO SF DO STATS FAZ ISSO ------##\n",
    "    #####-------------------------------------------------#####\n",
    "    \n",
    "    ## Função para calcular a probabilidade P(X=x), com x>=a.\n",
    "        \n",
    "    ## a = Um dos limites de integração, ou, um dos limites para a variável aleatória. \n",
    "    ## loc = média; usado para distribuição normal e exponencial.\n",
    "    ## scale = desvio padrão, usado para distribuição normal e exponencial.\n",
    "    ## avg_occurences = Número médio de ocorrências por unidade de tempo, comumente, lambda.\n",
    "    ## n = número de experimentos para as distribuições bernoulli e binomial.\n",
    "    ## p = probabilidade de um evento de bernoulli ou binomial.\n",
    "    ## kind = tipo de distribuição.\n",
    "    \n",
    "    \n",
    "    kinds = {\n",
    "        'poisson': False,\n",
    "        'binom': False,\n",
    "        'bern': False,\n",
    "        'expon': False\n",
    "    }\n",
    "    \n",
    "    if kind in kinds:\n",
    "        kinds[kind] = True\n",
    "        \n",
    "    if kinds['poisson']:\n",
    "        return 1 - poison.cdf(a,  mu = avg_occurences)\n",
    "    if kinds['binom']:\n",
    "        return 1 - binom.cdf(a,  n = n, p = p)\n",
    "    if kinds['bern']:\n",
    "        return 1 - bern.cdf(a, p = p)\n",
    "    if kinds['expon']:\n",
    "        return 1 - expon.cdf(a, loc = loc, scale = scale)\n",
    "    return 1 - norm.cdf(a, loc = loc, scale = scale)\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "def find_quantiles(percents = np.arange(0.25, 1,0.25), loc = 0, scale = 1, avg_occurences = 1, n = 1, p = 0.5,  kind = 'norm'):\n",
    "    \n",
    "    ## Função para calcular os percentis.\n",
    "        \n",
    "    ## percents = Lista (iterável), de 0 a 1, que contém os percentis que deseja-se obter.    \n",
    "    ## a = Um dos limites de integração, ou, um dos limites para a variável aleatória. \n",
    "    ## loc = média; usado para distribuição normal e exponencial.\n",
    "    ## scale = desvio padrão, usado para distribuição normal e exponencial.\n",
    "    ## avg_occurences = Número médio de ocorrências por unidade de tempo, comumente, lambda.\n",
    "    ## n = número de experimentos para as distribuições bernoulli e binomial.\n",
    "    ## p = probabilidade de um evento de bernoulli ou binomial.\n",
    "    ## kind = tipo de distribuição.\n",
    "    \n",
    "    \n",
    "    kinds = {\n",
    "        'poisson': False,\n",
    "        'binom': False,\n",
    "        'bern': False,\n",
    "        'expon': False\n",
    "    }\n",
    "    \n",
    "    if kind in kinds:\n",
    "        kinds[kind] = True\n",
    "        \n",
    "    if kinds['poisson']:\n",
    "        return [poison.ppf(i,  mu = avg_occurences) for i in percents]\n",
    "    if kinds['binom']:\n",
    "        return [binom.ppf(i,  n = n, p = p) for i in percents]\n",
    "    if kinds['bern']:\n",
    "        return [bern.ppf(i, p = p) for i in percents]\n",
    "    if kinds['expon']:\n",
    "        return [expon.ppf(i, loc = loc, scale = scale) for i in percents]\n",
    "    \n",
    "    return [norm.ppf(i, loc = loc, scale = scale) for i in percents]\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "def analise_dispersion(dataX, dataY, sort = True):\n",
    "    \n",
    "    ## Função que retorna um gráfico de dispersão dos dados, com linha de tendência, assim como a média e desvio padrão estimados.\n",
    "    \n",
    "    ## dataX e dataY = eixos do conjunto de dados a ser analisado. Podem ser listas ou séries do Pandas.\n",
    "    ## kind = tipo de distribuição esperada. Pode ser estimada com probplots ou multi_probplot.\n",
    "    \n",
    "    y = dataY\n",
    "    x = dataX \n",
    "    if sort:\n",
    "        # Se quiser que ordene seus dados, para melhorar visualização, deixe True.\n",
    "        y = sorted(dataY)\n",
    "    b, m = polyfit(x, y, 1)\n",
    "    f, ax1 = plt.subplots(figsize=(13, 10))     \n",
    "    ax1.plot(x, b + m * x, '-', lw = 2.5, color=\"green\", label = 'Tendência')\n",
    "    ax1.scatter(x, y)\n",
    "    ax1.legend()\n",
    "    corr = pd.Series(dataX).corr(pd.Series(dataY))\n",
    "    return ax1, corr #Plot, correlação de Pearson, respectivamente.\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "def cleanup(text):\n",
    "    import stringp\n",
    "    punctuation = '[!-.:?;]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    #text = ' '.join(word for word in text.split() if not word.startswith('ESCREVA OQ VC QUER TIRAR')) \n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed  \n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "def evaluate_relevance(treino1 = pd.Series([{'FAKEWORD':5}]), treino2 = pd.Series([{'FAKEWORD':5}]), text = \"\", alpha = 1, V = 100000):\n",
    "    \n",
    "    ## -Limpando os textos\n",
    "    text = cleanup(text)\n",
    "    \n",
    "    ## -- Calculando a probabilidade\n",
    "    sumR = 0\n",
    "    sumNR = 0\n",
    "    T_1 = (len(treino1)+alpha*V)\n",
    "    T_2 = (len(treino2)+alpha*V)\n",
    "    \n",
    "    for word in text.split():\n",
    "        \n",
    "        if word in treino1: \n",
    "            sumR += np.log((treino1[word]+alpha)/T_1)\n",
    "        else:\n",
    "            sumR += np.log(alpha/T_1)\n",
    "        if word in treino2: \n",
    "            sumNR += np.log((T_2[word]+alpha)/T_2)\n",
    "        else:\n",
    "            sumNR += np.log(alpha/T_2)\n",
    "    \n",
    "    return sumR>sumNR\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "def seleciona_coluna_qualitativa(data, coluna, tipo):\n",
    "    dados_selecionados = data[data[coluna] == tipo]\n",
    "    return dados_selecionados\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "def fit_data(data, kind = 'norm'):\n",
    "    \n",
    "    ## Função que retorna um histograma dos dados, com linha de destribuição teórica, assim como a média e desvio padrão estimados.\n",
    "    \n",
    "    ## data = Conjunto de dados a ser analisado. Pode ser uma lista ou série Pandas.\n",
    "    ## kind = tipo de distribuição esperada. Pode ser estimada com probplots ou multi_probplot.\n",
    "    \n",
    "    f, ax1 = plt.subplots(figsize=(13, 10), dpi = 60)\n",
    "    x = np.linspace(min(data), max(data), 500)\n",
    "    data = pd.Series(data)\n",
    "    if kind == 'expon':\n",
    "        loc, scale = expon.fit(data)\n",
    "        ax1.plot(x, expon.pdf(x, loc = loc, scale = scale))\n",
    "        ax1.hist(data, density = True)\n",
    "        return ax1, loc, scale\n",
    "    else:\n",
    "        loc, scale = norm.fit(data)\n",
    "        ax1.plot(x, norm.pdf(x, loc = loc, scale = scale))\n",
    "        ax1.hist(data, density = True)\n",
    "        return ax1, loc, scale\n",
    "    return -1,-1,[]\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "def multi_probplot(data, loc = 0, scale = 1, avg_occurences = 1, n = 1, p = 0.5):\n",
    "    \n",
    "    ## Função que gera os 4 probplots mais comuns.\n",
    "    \n",
    "    ## data = Conjunto de dados a ser analisado. Pode ser uma lista ou série Pandas.\n",
    "    ## loc = média; usado para distribuição normal e exponencial.\n",
    "    ## scale = desvio padrão, usado para distribuição normal e exponencial.\n",
    "    ## avg_occurences = Número médio de ocorrências por unidade de tempo, comumente, lambda.\n",
    "    ## n = número de experimentos para as distribuições bernoulli e binomial.\n",
    "    ## p = probabilidade de um evento de bernoulli ou binomial.\n",
    "    ## kind = tipo de distribuição.\n",
    "    \n",
    "    kinds = {\n",
    "        'poisson': \"Poisson\",\n",
    "        'binom': \"Binomial\",\n",
    "        'expon': \"Exponencial\",\n",
    "        'norm': 'Normal' \n",
    "    }\n",
    "        \n",
    "    for k,v in kinds.items():\n",
    "        if k == 'poisson':\n",
    "            probplot(data, sparams = (avg_occurences), plot = plt, dist = k)\n",
    "        if k == 'binom':\n",
    "            probplot(data, sparams = (n, p), plot = plt, dist = k)\n",
    "        if k == 'expon':\n",
    "            probplot(data, sparams = (loc, scale), plot = plt, dist = k)\n",
    "        if k == 'norm':\n",
    "            probplot(data, sparams = (loc, scale), plot = plt, dist = k)\n",
    "        plt.title(v)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICIONÁRIO:\n",
    "\n",
    "### Gráfico de dispersão: df.plot.scatter ou plt.scatter\n",
    "### Frequência absoluta: df.value_counts()\n",
    "### Frequência relativa: df.value_counts(normalize = True)\n",
    "### Histograma: df.hist(bins = n) \n",
    "### Histograma Freq Relativa: df.hist(density = True)\n",
    "### Correlação: df1.corr(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
